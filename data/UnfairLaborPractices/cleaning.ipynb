{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4717f24c-79cf-4c82-8a6a-9a14da1682bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ccf346-3bff-4c59-adef-ae54a444f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to import (avoids attempting to import empty columns)\n",
    "columns_to_import = [\"Case Type\",\"Region\",\"Case Number\",\"Case Name\",\"Status\",\"Date Filed\",\"Date Closed\",\"Reason Closed\"\n",
    "                     ,\"City\",\"States & Territories\",\"Employees on charge/petition\",\"Allegations\",\"Participants\",\"Union\",\n",
    "                     \"Unit Sought\",\"Voters\"]\n",
    "\n",
    "# Column data types, to avoid Pandas trying to parse data type on every column\n",
    "column_dtypes = {c:\"string\" for c in columns_to_import}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c827f6-8979-43e5-b910-5012ffd82ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import various partial data files, parsing dates in the date columns. All other columns are strings.\n",
    "df1978_1999 = pd.read_csv(\"1978-1999.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "\n",
    "# Note: broken entries in rows 10108 - 10111\n",
    "df2000_2004 = pd.read_csv(\"2000-2004.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2005_2009 = pd.read_csv(\"2005-2009.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2010 = pd.read_csv(\"2010.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2011 = pd.read_csv(\"2011.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2012 = pd.read_csv(\"2012.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2013 = pd.read_csv(\"2013.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2014 = pd.read_csv(\"2014.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "\n",
    "# Note: broken entry at row 1196 and 1197\n",
    "df2015_2019 = pd.read_csv(\"2015-2019.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2020_2024 = pd.read_csv(\"2020-2024.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fac5ea1c-27b9-4299-9ecb-b0150a52e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As imported, data files are descending in date. Concatenate into one large data file.\n",
    "# According to NLRB website, we should have 412094 cases, but we get 413889 rows. The overcount\n",
    "# is probably due to rows that broke while downloading. TODO: check which years need to be redone.\n",
    "unfair_labor_practices = pd.concat([df2020_2024, df2015_2019, df2014, df2013, df2012, df2011, df2010, df2005_2009, df2000_2004, df1978_1999], ignore_index = True)\n",
    "\n",
    "# When imported, missing values became \"<NA>\". Replace these with NaT to match usual Pandas convention by \n",
    "# replacing \"<NA>\" by pd.NaT, then using to_datetime and coercing NaTs.\n",
    "unfair_labor_practices[\"Date Closed\"] = pd.to_datetime(unfair_labor_practices[\"Date Closed\"].replace(\"<NA>\", pd.NaT), errors = \"coerce\")\n",
    "unfair_labor_practices[\"Date Filed\"] = pd.to_datetime(unfair_labor_practices[\"Date Filed\"].replace(\"<NA>\", pd.NaT), errors = \"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccb17733-2b6d-475d-9303-ce07a7e9fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove entries where case type is not \"C\" (removes accidentally included representation petitions,\n",
    "# which are the vast majority of removed entries, plus some broken entries)\n",
    "unfair_labor_practices = unfair_labor_practices[unfair_labor_practices[\"Case Type\"] == \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c057eab8-f1ec-45e5-9ab7-4413bae3c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove broken entries by checking case number formatting\n",
    "unfair_labor_practices = unfair_labor_practices[unfair_labor_practices[\"Case Number\"].str.match(r'..-..-*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "318c0702-000e-4cee-ac16-a1261f309473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2000: 3919, 2001: 5164, 2002: 7595, 2003: 9135, 2004: 7252, 2005: 8911, 2006: 13048, 2007: 22987, 2008: 22190, 2009: 24849, 2010: 23671, 2011: 21469, 2012: 21216, 2013: 21334, 2014: 24152, 2015: 20044, 2016: 21032, 2017: 19146, 2018: 18891, 2019: 18343, 2020: 15139, 2021: 15534, 2022: 18609, 2023: 20305, 2024: 6099}\n"
     ]
    }
   ],
   "source": [
    "# Print case counts by year.\n",
    "print({year: unfair_labor_practices[unfair_labor_practices[\"Date Filed\"].dt.year == year].shape[0] for year in range(2000,2025)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b5e5868-81b9-4b25-815f-b824f1f03521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the ones that match NLRBs website counts (pre-2000 in separate file)\n",
    "unfair_labor_practices[unfair_labor_practices[\"Date Filed\"].dt.year < 2000].drop_duplicates().to_csv(\"cleaned/pre2000.csv\")\n",
    "for year in [2000,2001,2002,2005, 2006,2007,2008, 2010, 2011, 2012, 2015, 2016, 2017, 2018, 2021]:\n",
    "    filt = (unfair_labor_practices[\"Date Filed\"].dt.year == year)\n",
    "    unfair_labor_practices[filt].drop_duplicates().to_csv(\"cleaned/\"+str(year)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c572613c-d5f3-4a20-b85c-7d4e57472555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process manually downloaded CSVs for years that didn't match NLRB website.\n",
    "# These CSVs also don't quite match the NLRB website count but at least are devoid\n",
    "# of broken entries.\n",
    "df2003 = pd.read_csv(\"2003.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2004 = pd.read_csv(\"2004.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2009 = pd.read_csv(\"2009.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2013 = pd.read_csv(\"2013.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2014 = pd.read_csv(\"2014.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2019 = pd.read_csv(\"2019.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2020 = pd.read_csv(\"2020.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2022 = pd.read_csv(\"2022.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2023 = pd.read_csv(\"2023.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")\n",
    "df2024 = pd.read_csv(\"2024.csv\", usecols = columns_to_import, dtype = column_dtypes, parse_dates = [\"Date Filed\", \"Date Closed\"], date_format = \"%m%d%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd6b22ce-79b7-4f11-8d07-72dbb5b227e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfair_labor_practices_fix = pd.concat([df2003,df2004,df2009,df2013,df2014,df2019,df2020,df2022,df2023,df2024], ignore_index = True)\n",
    "\n",
    "# When imported, missing values became \"<NA>\". Replace these with NaT to match usual Pandas convention by \n",
    "# replacing \"<NA>\" by pd.NaT, then using to_datetime and coercing NaTs.\n",
    "unfair_labor_practices_fix[\"Date Closed\"] = pd.to_datetime(unfair_labor_practices_fix[\"Date Closed\"].replace(\"<NA>\", pd.NaT), errors = \"coerce\")\n",
    "unfair_labor_practices_fix[\"Date Filed\"] = pd.to_datetime(unfair_labor_practices_fix[\"Date Filed\"].replace(\"<NA>\", pd.NaT), errors = \"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b31e434c-3bd9-4f9a-9bf6-00f737f5a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove accidentally included representation petitions\n",
    "unfair_labor_practices_fix = unfair_labor_practices_fix[unfair_labor_practices_fix[\"Case Type\"] == \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7639e59-9500-47ee-84fb-362b61525002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove broken entries by checking case number formatting\n",
    "unfair_labor_practices_fix = unfair_labor_practices_fix[unfair_labor_practices_fix[\"Case Number\"].str.match(r'..-..-*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5696e31-05ef-4b07-9be4-d59bfd5dd827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export remaining years\n",
    "for year in [2003, 2004, 2009, 2013, 2014, 2019, 2020, 2022, 2023, 2024]:\n",
    "    filt = (unfair_labor_practices_fix[\"Date Filed\"].dt.year == year)\n",
    "    unfair_labor_practices_fix[filt].drop_duplicates().to_csv(\"cleaned/\"+str(year)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11407c39-9199-41a7-acf0-806db8e49f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
